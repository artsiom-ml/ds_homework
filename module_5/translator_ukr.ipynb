{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from io import open\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class LanguageVocabulary(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 156173 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 10085\n",
      "ukr 30616\n",
      "['i don t trust you .', 'я тобі не довіряю .']\n"
     ]
    }
   ],
   "source": [
    "class Preprocessing:\n",
    "\n",
    "    # DATA_DIR = '/content/drive/My Drive/Colab Notebooks/translation_data/'\n",
    "    DATA_DIR = './translation_data/'\n",
    "\n",
    "    def __init__(self, lang, reverse=False):\n",
    "        self.lang = lang\n",
    "        self.source_path = os.path.join(self.DATA_DIR, lang + '.txt')\n",
    "        self.target_path = os.path.join(self.DATA_DIR, 'eng-' + lang + '.txt')\n",
    "        self.reverse = reverse\n",
    "\n",
    "    @staticmethod\n",
    "    def unicode_to_ascii(s):\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "        )\n",
    "\n",
    "    def normalize_string(self, s):\n",
    "        s = self.unicode_to_ascii(s.lower().strip())\n",
    "        s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "        s = re.sub(r\"[^a-zA-Zа-яА-Яє-їЄ-Ї.!?]+\", r\" \", s)\n",
    "        # s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "        return s\n",
    "\n",
    "    def prepare_file(self, source_path, target_path):\n",
    "        with open(source_path, encoding='utf-8') as file1, open(target_path, 'w', encoding='utf-8') as file2:\n",
    "            for line in file1:\n",
    "                file2.write(line.strip().split('\\t')[0] + '\\t' + line.strip().split('\\t')[1] + '\\n')\n",
    "\n",
    "    def prepare_data(self, lang1, lang2, reverse=False):\n",
    "        input_lang, output_lang, pairs = self.read_languages(lang1, lang2, reverse)\n",
    "        print(\"Read %s sentence pairs\" % len(pairs))\n",
    "        print(\"Counting words...\")\n",
    "        for pair in pairs:\n",
    "            input_lang.add_sentence(pair[0])\n",
    "            output_lang.add_sentence(pair[1])\n",
    "        print(\"Counted words:\")\n",
    "        print(input_lang.name, input_lang.n_words)\n",
    "        print(output_lang.name, output_lang.n_words)\n",
    "        return input_lang, output_lang, pairs\n",
    "\n",
    "    def read_languages(self, lang1, lang2, reverse=False):\n",
    "        print(\"Reading lines...\")\n",
    "        path = os.path.join(self.DATA_DIR, '%s-%s.txt' % (lang1, lang2))\n",
    "        lines = open(path, encoding='utf-8').read().strip().split('\\n')\n",
    "        pairs = [[self.normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "        if reverse:\n",
    "            pairs = [list(reversed(p)) for p in pairs]\n",
    "            input_lang = LanguageVocabulary(lang2)\n",
    "            output_lang = LanguageVocabulary(lang1)\n",
    "        else:\n",
    "            input_lang = LanguageVocabulary(lang1)\n",
    "            output_lang = LanguageVocabulary(lang2)\n",
    "        return input_lang, output_lang, pairs\n",
    "\n",
    "    def get_data(self):\n",
    "        self.prepare_file(self.source_path, self.target_path)\n",
    "        input_lang, output_lang, pairs = self.prepare_data('eng', self.lang, self.reverse)\n",
    "        return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = Preprocessing(lang='ukr').get_data()\n",
    "print(random.choice(pairs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def get_max_length(pairs):\n",
    "  max_length = 0\n",
    "  for pair in pairs:\n",
    "    max_in_pair = max(len(pair[0]), len(pair[1]))\n",
    "    if max_in_pair > max_length:\n",
    "      max_length = max_in_pair\n",
    "  return max_length\n",
    "MAX_LENGTH = get_max_length(pairs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    loss = 0\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    if use_teacher_forcing:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    return loss.item() / target_length"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / percent\n",
    "    rs = es - s\n",
    "    return '%s (- eta: %s)' % (asMinutes(s), asMinutes(rs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[epoch - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_iters),\n",
    "                                         epoch, epoch / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    showPlot(plot_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for i in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
    "            encoder_outputs[i] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        return decoded_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    candidate_corpus = []\n",
    "    references_corpus = []\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        references_corpus.append(pair[1].split(' '))\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        candidate_corpus.append(output_words)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "    print('Blue score = ', bleu_score(candidate_corpus, references_corpus, max_n=1, weights=[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "hidden_size = 256"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_56t10oM9uh",
    "outputId": "b8da72e8-ca6d-4d1e-9892-7963d5adb043",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1664105386055,
     "user_tz": -180,
     "elapsed": 4100991,
     "user": {
      "displayName": "Artem",
      "userId": "12316757087123183587"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1m 32s (- eta: 75m 49s) (5000 2%) 5.0252\n",
      "2m 52s (- eta: 69m 2s) (10000 4%) 4.5566\n",
      "4m 13s (- eta: 66m 8s) (15000 6%) 4.2489\n",
      "5m 36s (- eta: 64m 24s) (20000 8%) 4.0173\n",
      "6m 56s (- eta: 62m 31s) (25000 10%) 3.8550\n",
      "8m 17s (- eta: 60m 48s) (30000 12%) 3.7310\n",
      "9m 38s (- eta: 59m 13s) (35000 14%) 3.5877\n",
      "10m 58s (- eta: 57m 39s) (40000 16%) 3.5022\n",
      "12m 20s (- eta: 56m 11s) (45000 18%) 3.4080\n",
      "13m 43s (- eta: 54m 52s) (50000 20%) 3.3255\n",
      "15m 4s (- eta: 53m 27s) (55000 22%) 3.2612\n",
      "16m 25s (- eta: 52m 0s) (60000 24%) 3.1990\n",
      "17m 46s (- eta: 50m 35s) (65000 26%) 3.1125\n",
      "19m 7s (- eta: 49m 11s) (70000 28%) 3.0998\n",
      "20m 29s (- eta: 47m 49s) (75000 30%) 3.0050\n",
      "21m 52s (- eta: 46m 29s) (80000 32%) 2.9912\n",
      "23m 14s (- eta: 45m 7s) (85000 34%) 2.9808\n",
      "24m 36s (- eta: 43m 44s) (90000 36%) 2.8970\n",
      "25m 57s (- eta: 42m 20s) (95000 38%) 2.8491\n",
      "27m 18s (- eta: 40m 57s) (100000 40%) 2.8135\n",
      "28m 41s (- eta: 39m 37s) (105000 42%) 2.7844\n",
      "30m 2s (- eta: 38m 14s) (110000 44%) 2.7551\n",
      "31m 23s (- eta: 36m 51s) (115000 46%) 2.7401\n",
      "32m 45s (- eta: 35m 29s) (120000 48%) 2.6781\n",
      "34m 6s (- eta: 34m 6s) (125000 50%) 2.6412\n",
      "35m 27s (- eta: 32m 44s) (130000 52%) 2.6231\n",
      "36m 50s (- eta: 31m 22s) (135000 54%) 2.5685\n",
      "38m 12s (- eta: 30m 0s) (140000 56%) 2.6010\n",
      "39m 33s (- eta: 28m 38s) (145000 57%) 2.5834\n",
      "40m 54s (- eta: 27m 16s) (150000 60%) 2.5376\n",
      "42m 16s (- eta: 25m 54s) (155000 62%) 2.5124\n",
      "43m 38s (- eta: 24m 32s) (160000 64%) 2.4850\n",
      "45m 1s (- eta: 23m 11s) (165000 66%) 2.4819\n",
      "46m 22s (- eta: 21m 49s) (170000 68%) 2.4553\n",
      "47m 44s (- eta: 20m 27s) (175000 70%) 2.4371\n",
      "49m 6s (- eta: 19m 5s) (180000 72%) 2.4306\n",
      "50m 28s (- eta: 17m 44s) (185000 74%) 2.4013\n",
      "51m 50s (- eta: 16m 22s) (190000 76%) 2.3535\n",
      "53m 13s (- eta: 15m 0s) (195000 78%) 2.3620\n",
      "54m 36s (- eta: 13m 39s) (200000 80%) 2.3569\n",
      "55m 58s (- eta: 12m 17s) (205000 82%) 2.3175\n",
      "57m 19s (- eta: 10m 55s) (210000 84%) 2.2926\n",
      "58m 41s (- eta: 9m 33s) (215000 86%) 2.3055\n",
      "60m 4s (- eta: 8m 11s) (220000 88%) 2.2761\n",
      "61m 27s (- eta: 6m 49s) (225000 90%) 2.2787\n",
      "62m 48s (- eta: 5m 27s) (230000 92%) 2.2422\n",
      "64m 10s (- eta: 4m 5s) (235000 94%) 2.2131\n",
      "65m 32s (- eta: 2m 43s) (240000 96%) 2.2136\n",
      "66m 54s (- eta: 1m 21s) (245000 98%) 2.1976\n",
      "68m 19s (- eta: 0m 0s) (250000 100%) 2.2081\n"
     ]
    }
   ],
   "source": [
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "trainIters(encoder1, decoder1, 250000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_enc(path):\n",
    "    model = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "    model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_dec(path):\n",
    "    model = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "    model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# save_model(encoder1, 'encoder_ukr_eng_v3.pt')\n",
    "# save_model(decoder1, 'decoder_ukr_eng_v3.pt')"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "onH6aaCmbYFM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1664105434140,
     "user_tz": -180,
     "elapsed": 217,
     "user": {
      "displayName": "Artem",
      "userId": "12316757087123183587"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> i walk quickly .\n",
      "= я швидко ходжу .\n",
      "< я швидко швидко . <EOS>\n",
      "\n",
      "> tom pressed the wrong button .\n",
      "= том натиснув не на ту кнопку .\n",
      "< том натиснув цеи кнопку кнопку . <EOS>\n",
      "\n",
      "> tom s wife had a baby girl yesterday .\n",
      "= жінка тома вчора народила дівчинку .\n",
      "< дружина тома тома дружина у дружина вчора . . <EOS>\n",
      "\n",
      "> i failed the exam because i didn t study .\n",
      "= я провалив екзамен бо я не вчився .\n",
      "< я не був бо бо я я я . <EOS>\n",
      "\n",
      "> tom s packing .\n",
      "= том збирає валізи .\n",
      "< том тома . <EOS>\n",
      "\n",
      "> the movie is worth seeing at least two or three times .\n",
      "= фільм вартии того щоб иого переглянути щонаименше двічі чи тричі .\n",
      "< цеи фільм тут варто був у . . . <EOS>\n",
      "\n",
      "> the question is do you know what you re doing .\n",
      "= питання в тому чи ти знаєш що ти робиш .\n",
      "< проблема це що що ви . . <EOS>\n",
      "\n",
      "> i m going to the bank .\n",
      "= я иду до банку .\n",
      "< я іду до банку . <EOS>\n",
      "\n",
      "> i don t get invited to parties anymore .\n",
      "= мене більше не запрошують на вечірки .\n",
      "< мене не не не чекати . <EOS>\n",
      "\n",
      "> tom s smarter than mary .\n",
      "= том розумнішии за мері .\n",
      "< том розумнішии за мері . <EOS>\n",
      "\n",
      "Blue score =  0.2054794430732727\n"
     ]
    }
   ],
   "source": [
    "encoder1 = load_enc('encoder_ukr_eng_v3.pt')\n",
    "decoder1 = load_dec('decoder_ukr_eng_v3.pt')\n",
    "\n",
    "evaluateRandomly(encoder1, decoder1)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "6mYNwDkJbYFM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "23ceb7112fbf9d0e38ecbf60d6e6d5e2dcebcc82200eeb1e5a5d5f9ffb9e27ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}