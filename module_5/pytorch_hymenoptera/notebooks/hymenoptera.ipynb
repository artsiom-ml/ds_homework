{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision as tv\n",
    "import time\n",
    "from torchvision import datasets, models, transforms\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "data_dir= '../input/hymenoptera_data/hymenoptera_data'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), data_transforms['train'])\n",
    "test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'), data_transforms['val'])\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1534, -0.6740],\n",
      "        [ 0.6922, -0.5466],\n",
      "        [ 1.3871, -0.0320],\n",
      "        [ 1.5880, -1.2704]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 6.2296, -5.5126],\n",
      "        [ 4.1795, -1.3518],\n",
      "        [-5.2100,  4.7924],\n",
      "        [ 1.7758,  0.0703]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 2.7469, -1.9797],\n",
      "        [ 3.8616, -3.3273],\n",
      "        [ 5.1585, -3.9227],\n",
      "        [ 5.5832, -3.2029]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 5.5474, -3.4183],\n",
      "        [ 0.8089,  1.4567],\n",
      "        [ 4.5543, -2.8858],\n",
      "        [ 7.4123, -6.4605]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 5.9560, -4.8910],\n",
      "        [ 0.1199,  1.2136],\n",
      "        [ 1.8279, -0.4323],\n",
      "        [ 3.4962, -2.1025]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 1.7365, -0.5570],\n",
      "        [ 3.6902, -3.9496],\n",
      "        [-1.4588,  2.9625],\n",
      "        [-0.2186,  0.2968]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 3.9215, -1.8141],\n",
      "        [ 3.3933, -2.7079],\n",
      "        [ 6.2242, -4.9571],\n",
      "        [ 3.6139, -3.2246]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 2.1262, -1.4277],\n",
      "        [-1.1028,  4.1168],\n",
      "        [ 6.0376, -4.0879],\n",
      "        [ 0.6409,  0.3049]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 4.0613, -2.9880],\n",
      "        [ 6.0568, -5.3964],\n",
      "        [ 2.8558, -1.3788],\n",
      "        [ 4.4195, -2.6882]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 1.4250, -0.1200],\n",
      "        [ 2.0021, -1.7201],\n",
      "        [ 8.1018, -6.9844],\n",
      "        [ 2.2020, -0.7961]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 0.8893,  0.4762],\n",
      "        [-1.6149,  2.4975],\n",
      "        [ 3.3418, -2.3386],\n",
      "        [ 6.0331, -4.6789]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 0.2274,  0.2488],\n",
      "        [ 8.8909, -7.4354],\n",
      "        [ 1.6691, -1.1330],\n",
      "        [ 0.3825,  1.5701]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 1.1013, -0.2050],\n",
      "        [ 3.5647, -1.6622],\n",
      "        [ 2.7031, -0.1976],\n",
      "        [ 2.6567, -1.3599]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 1.5515, -0.3743],\n",
      "        [ 2.9750, -2.8509],\n",
      "        [ 1.6172, -0.5124],\n",
      "        [ 3.1153, -1.6932]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 1.5877, -0.8643],\n",
      "        [ 4.4893, -3.2579],\n",
      "        [ 3.5938, -1.8662],\n",
      "        [ 0.9036, -0.4827]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 0.7294, -0.3486],\n",
      "        [-0.6378,  1.7947],\n",
      "        [ 4.2614, -3.5875],\n",
      "        [-0.1849,  1.4808]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 6.1074, -6.7058],\n",
      "        [ 5.8149, -4.1580],\n",
      "        [ 2.7784, -1.8909],\n",
      "        [ 3.1651, -3.3678]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 4.4731, -2.6786],\n",
      "        [ 3.6118, -2.9485],\n",
      "        [-6.8907,  8.7113],\n",
      "        [-2.7832,  3.7903]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 1, 1])\n",
      "tensor([[-3.0383,  5.4446],\n",
      "        [-8.4246,  8.8298],\n",
      "        [-5.4612,  7.1607],\n",
      "        [-4.7187,  5.7837]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-4.5234,  7.2125],\n",
      "        [-3.0295,  3.8955],\n",
      "        [-5.6739,  6.9669],\n",
      "        [-4.8613,  6.6566]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[ -5.9890,   8.8618],\n",
      "        [ -1.9103,   2.0691],\n",
      "        [-13.0285,  15.3636],\n",
      "        [ -9.9418,  11.5101]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-4.6554,  5.8802],\n",
      "        [-6.7711,  8.4166],\n",
      "        [-9.4005, 10.9017],\n",
      "        [-9.1294, 10.4246]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-3.6852,  4.5853],\n",
      "        [-3.9910,  5.1977],\n",
      "        [-4.5617,  7.1515],\n",
      "        [-7.4213,  8.5051]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-7.2548,  8.0022],\n",
      "        [-8.0589, 10.6462],\n",
      "        [-9.5002, 10.5984],\n",
      "        [-9.6464, 12.2474]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-5.4517,  6.9216],\n",
      "        [-3.8837,  5.6608],\n",
      "        [-7.3209,  8.0164],\n",
      "        [-3.4946,  5.9841]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-6.8353,  8.3354],\n",
      "        [-5.4293,  7.3302],\n",
      "        [-5.9734,  7.3040],\n",
      "        [-3.9198,  4.8364]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-5.1652,  6.8345],\n",
      "        [-0.9770,  1.8654],\n",
      "        [-3.1788,  3.9406],\n",
      "        [-4.5867,  4.8993]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-6.5424,  7.5454],\n",
      "        [-6.6811,  7.3486],\n",
      "        [-3.0924,  4.7322],\n",
      "        [-1.5798,  2.0145]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[ -5.8480,   7.1390],\n",
      "        [-12.4967,  13.7083],\n",
      "        [ -1.1904,   3.7721],\n",
      "        [ -5.7524,   6.9043]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-8.8203, 11.5831],\n",
      "        [-2.7695,  4.6713],\n",
      "        [-6.5887,  7.9763],\n",
      "        [-5.3869,  6.6483]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[ -7.0352,   9.1583],\n",
      "        [-11.8797,  12.2808],\n",
      "        [ -4.5884,   5.9777],\n",
      "        [ -9.2183,   9.7673]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-8.3706,  9.4126],\n",
      "        [-6.7083,  6.6034],\n",
      "        [-8.9517,  8.8279],\n",
      "        [-5.5481,  6.4471]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-6.2309,  7.2959],\n",
      "        [-3.8630,  5.5645],\n",
      "        [-2.6988,  3.9423],\n",
      "        [-8.2943,  9.7706]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-2.3414,  4.5222],\n",
      "        [-5.5636,  7.3088],\n",
      "        [-7.1376,  8.3748],\n",
      "        [-5.3241,  7.1956]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[ 0.9623,  0.4820],\n",
      "        [ 0.0910,  0.5914],\n",
      "        [-8.4359, 10.8325],\n",
      "        [-0.6331,  1.7147]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-2.7565,  5.1831],\n",
      "        [-5.4516,  6.2683],\n",
      "        [-5.1290,  7.6426],\n",
      "        [-4.8087,  6.0132]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[ 2.4988, -1.1436],\n",
      "        [-5.5897,  6.6887],\n",
      "        [-2.2034,  3.9838],\n",
      "        [-5.4486,  7.1132]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-2.8780,  4.7635],\n",
      "        [-6.3775,  8.1614],\n",
      "        [-2.3430,  4.4275],\n",
      "        [-9.0791, 10.3458]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([[-8.2174,  9.0185]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9150326797385621"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(test_iter, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = torch.Tensor([0]), 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        print(net(X))\n",
    "        print(y)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            # print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "            #     (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, input_channels, num_channels):\n",
    "\n",
    "    block = nn.Sequential(\n",
    "        nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "    for i in range(num_convs - 1):\n",
    "        block.add_module(\"conv{}\".format(i),\n",
    "                         nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "                         )\n",
    "        block.add_module(\"relu{}\".format(i),\n",
    "                         nn.ReLU()\n",
    "                         )\n",
    "\n",
    "    block.add_module(\"pool\", nn.MaxPool2d(2, stride=2))\n",
    "\n",
    "    return block"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "conv_arch = ((1, 1, 64), (1, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    net = nn.Sequential()\n",
    "\n",
    "    for i, (num_convs, input_ch, num_channels) in enumerate(conv_arch):\n",
    "        net.add_module(\"block{}\".format(i), vgg_block(num_convs, input_ch, num_channels))\n",
    "\n",
    "\n",
    "    classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(25088, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 2))\n",
    "\n",
    "    net.add_module('classifier', classifier)\n",
    "    return net\n",
    "\n",
    "net = vgg(conv_arch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = models.vgg16()\n",
    "net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_vgg16 = models.vgg16()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(in_features=512, out_features=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# model_vgg16.classifier = torch.nn.Linear(25088, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight                      False\n",
      "0.bias                        False\n",
      "2.weight                      False\n",
      "2.bias                        False\n",
      "5.weight                      False\n",
      "5.bias                        False\n",
      "7.weight                      False\n",
      "7.bias                        False\n",
      "10.weight                     False\n",
      "10.bias                       False\n",
      "12.weight                     False\n",
      "12.bias                       False\n",
      "14.weight                     False\n",
      "14.bias                       False\n",
      "17.weight                     False\n",
      "17.bias                       False\n",
      "19.weight                     False\n",
      "19.bias                       False\n",
      "21.weight                     False\n",
      "21.bias                       False\n",
      "24.weight                     False\n",
      "24.bias                       False\n",
      "26.weight                     False\n",
      "26.bias                       False\n",
      "28.weight                     False\n",
      "28.bias                       False\n"
     ]
    }
   ],
   "source": [
    "# layers_to_freeze = 30\n",
    "# for i, (name, param) in enumerate(model_vgg16.features.named_parameters()):\n",
    "#     if i < layers_to_freeze:\n",
    "#         param.requires_grad = False\n",
    "#     print(f'{name:30}{param.requires_grad}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.9659, train acc 0.631, test acc 0.582, time 13.4 sec\n",
      "epoch 2, loss 0.6339, train acc 0.775, test acc 0.758, time 12.7 sec\n",
      "epoch 3, loss 0.3431, train acc 0.877, test acc 0.719, time 13.1 sec\n",
      "epoch 4, loss 0.3644, train acc 0.889, test acc 0.778, time 12.6 sec\n",
      "epoch 5, loss 0.3332, train acc 0.873, test acc 0.745, time 12.5 sec\n",
      "epoch 6, loss 0.3126, train acc 0.861, test acc 0.712, time 12.6 sec\n",
      "epoch 7, loss 0.2946, train acc 0.885, test acc 0.863, time 12.5 sec\n",
      "epoch 8, loss 0.2970, train acc 0.889, test acc 0.758, time 12.5 sec\n",
      "epoch 9, loss 0.2695, train acc 0.885, test acc 0.843, time 12.6 sec\n",
      "epoch 10, loss 0.2550, train acc 0.902, test acc 0.824, time 12.6 sec\n",
      "epoch 11, loss 0.2572, train acc 0.865, test acc 0.830, time 12.6 sec\n",
      "epoch 12, loss 0.2617, train acc 0.885, test acc 0.850, time 12.7 sec\n",
      "epoch 13, loss 0.2018, train acc 0.922, test acc 0.902, time 12.6 sec\n",
      "epoch 14, loss 0.2056, train acc 0.934, test acc 0.869, time 12.6 sec\n",
      "epoch 15, loss 0.1595, train acc 0.926, test acc 0.869, time 13.4 sec\n",
      "epoch 16, loss 0.2329, train acc 0.902, test acc 0.817, time 13.0 sec\n",
      "epoch 17, loss 0.2781, train acc 0.893, test acc 0.804, time 12.5 sec\n",
      "epoch 18, loss 0.2833, train acc 0.902, test acc 0.817, time 13.7 sec\n",
      "epoch 19, loss 0.2975, train acc 0.906, test acc 0.895, time 12.8 sec\n",
      "epoch 20, loss 0.1901, train acc 0.926, test acc 0.902, time 13.0 sec\n",
      "epoch 21, loss 0.2206, train acc 0.918, test acc 0.850, time 13.6 sec\n",
      "epoch 22, loss 0.2326, train acc 0.902, test acc 0.863, time 12.6 sec\n",
      "epoch 23, loss 0.2246, train acc 0.926, test acc 0.810, time 12.7 sec\n",
      "epoch 24, loss 0.1942, train acc 0.926, test acc 0.908, time 12.8 sec\n",
      "epoch 25, loss 0.2114, train acc 0.918, test acc 0.850, time 12.7 sec\n",
      "epoch 26, loss 0.2013, train acc 0.918, test acc 0.908, time 12.6 sec\n",
      "epoch 27, loss 0.1970, train acc 0.918, test acc 0.908, time 12.8 sec\n",
      "epoch 28, loss 0.1229, train acc 0.951, test acc 0.922, time 12.6 sec\n",
      "epoch 29, loss 0.1264, train acc 0.951, test acc 0.915, time 12.7 sec\n",
      "epoch 30, loss 0.2020, train acc 0.939, test acc 0.863, time 12.7 sec\n",
      "epoch 31, loss 0.1303, train acc 0.955, test acc 0.915, time 12.6 sec\n",
      "epoch 32, loss 0.1256, train acc 0.930, test acc 0.922, time 13.1 sec\n",
      "epoch 33, loss 0.1495, train acc 0.943, test acc 0.915, time 12.7 sec\n",
      "epoch 34, loss 0.1492, train acc 0.947, test acc 0.915, time 12.7 sec\n",
      "epoch 35, loss 0.1302, train acc 0.955, test acc 0.908, time 12.7 sec\n",
      "epoch 36, loss 0.1653, train acc 0.939, test acc 0.876, time 12.5 sec\n",
      "epoch 37, loss 0.1481, train acc 0.926, test acc 0.928, time 12.6 sec\n",
      "epoch 38, loss 0.1366, train acc 0.955, test acc 0.902, time 12.7 sec\n",
      "epoch 39, loss 0.1756, train acc 0.939, test acc 0.908, time 12.8 sec\n",
      "epoch 40, loss 0.0940, train acc 0.963, test acc 0.895, time 12.7 sec\n",
      "epoch 41, loss 0.1452, train acc 0.939, test acc 0.915, time 13.4 sec\n",
      "epoch 42, loss 0.1174, train acc 0.955, test acc 0.895, time 12.6 sec\n",
      "epoch 43, loss 0.2324, train acc 0.939, test acc 0.869, time 12.6 sec\n",
      "epoch 44, loss 0.1631, train acc 0.926, test acc 0.889, time 12.7 sec\n",
      "epoch 45, loss 0.1557, train acc 0.934, test acc 0.895, time 12.8 sec\n",
      "epoch 46, loss 0.1757, train acc 0.934, test acc 0.863, time 13.1 sec\n",
      "epoch 47, loss 0.1874, train acc 0.930, test acc 0.850, time 13.3 sec\n",
      "epoch 48, loss 0.1624, train acc 0.943, test acc 0.915, time 12.8 sec\n",
      "epoch 49, loss 0.2107, train acc 0.934, test acc 0.824, time 12.8 sec\n",
      "epoch 50, loss 0.1465, train acc 0.934, test acc 0.915, time 12.6 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 50\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train(model, train_iter, test_iter, trainer, num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2, bias=True)\n)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_vgg = tv.models.vgg16(pretrained=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([2], dtype=int64)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([[1],[3], [6]]).argmax(axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 1, 0], dtype=int64)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[ 1.1534, -0.6740],\n",
    "        [ 0.6922, -0.5466],\n",
    "        [ 1.3871, 2.0320],\n",
    "        [ 1.5880, -1.2704]]).argmax(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}